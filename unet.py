# -*- coding: utf-8 -*-
"""unet.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZSV55yevy7egxarRFtF1AdIiZUh7QbmS
"""

pip install lpips

import os
import cv2
import random
from PIL import Image

import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision.transforms import transforms
from torchvision import datasets
from torch.utils.data import DataLoader, Dataset, random_split, Subset
from torchmetrics.functional.image.ssim import structural_similarity_index_measure as ssim
import lpips

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

root = '/kaggle/working/'
full_train_set = datasets.CIFAR100(root, train=True,  download=True)
full_test_set  = datasets.CIFAR100(root, train=False, download=True)

g = torch.Generator().manual_seed(42)

train_set, val_set = random_split(full_train_set, [40_000, 10_000], generator=g)

test_indices = torch.randperm(len(full_test_set), generator=g)[:10_000]
test_set = Subset(full_test_set, test_indices)

class RandomWhiteOut:
    def __init__(self, scale=(0.02, 0.05), ratio=(0.3, 3.3)):
        self.scale = scale
        self.ratio = ratio

    def __call__(self, img):
        if isinstance(img, torch.Tensor):
            img = transforms.ToPILImage()(img)

        w, h = img.size
        area = h * w
        img_np = np.array(img, copy=True)
        mask_np = np.zeros((h, w), dtype=np.uint8)

        for _ in range(10):
            target_area = random.uniform(*self.scale) * area
            aspect_ratio = random.uniform(*self.ratio)

            erase_w = int(round((target_area * aspect_ratio) ** 0.5))
            erase_h = int(round((target_area / aspect_ratio) ** 0.5))

            if erase_w <= w and erase_h <= h:
                x1 = random.randint(0, w - erase_w)
                y1 = random.randint(0, h - erase_h)

                img_np[y1:y1+erase_h, x1:x1+erase_w, :] = 255
                mask_np[y1:y1+erase_h, x1:x1+erase_w] = 1

                break

        noisy_tensor = transforms.ToTensor()(img_np)
        mask_tensor = torch.from_numpy(mask_np)[None].float()
        return noisy_tensor, mask_tensor

class UNetDataset(Dataset):
    def __init__(self, dataset, clean_tf=None, noisy_tf=None):
        self.dataset = dataset
        self.clean_tf = clean_tf or transforms.ToTensor()
        self.noisy_tf = noisy_tf or RandomWhiteOut()
        super().__init__()

    def __len__(self):
        return len(self.dataset)

    def __getitem__(self, idx):
        img, _ = self.dataset[idx]
        clean_img = self.clean_tf(img)
        noisy_img, mask = self.noisy_tf(img)
        return noisy_img, clean_img, mask

train_dataset = UNetDataset(train_set)
val_dataset = UNetDataset(val_set)
test_dataset = UNetDataset(test_set)

train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2, pin_memory=True)
val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=2, pin_memory=True)
test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2, pin_memory=True)

class EncoderLayer(nn.Module):
    def __init__(self, cin, cout, kernel=3, stride=1, pad=1):
        super().__init__()
        self.conv = nn.Conv2d(cin, cout, kernel, stride, pad)
        self.relu = nn.ReLU(inplace=True)

    def forward(self, x):
        out = self.conv(x)
        return self.relu(out)

class EncoderBlock(nn.Module):
    def __init__(self, cin, cout, conv_kernel=3, conv_pad=1, conv_stride=1,
                 has_pool=True, pool_kernel=2, pool_stride=2):
        super().__init__()
        self.layer1 = EncoderLayer(cin, cout, conv_kernel, conv_stride, conv_pad)
        self.layer2 = EncoderLayer(cout, cout, conv_kernel, conv_stride, conv_pad)
        self.pool = nn.Identity()
        if has_pool:
            self.pool = nn.MaxPool2d(pool_kernel, pool_stride)

    def forward(self, x):
        pre_pool = self.layer1(x)
        pre_pool = self.layer2(pre_pool)
        post_pool = self.pool(pre_pool)
        return pre_pool, post_pool

class Encoder(nn.Module):
    def __init__(self):
        super().__init__()
        self.block1 = EncoderBlock(3, 64)
        self.block2 = EncoderBlock(64, 128)
        self.block3 = EncoderBlock(128, 256)
        self.bottleneck = EncoderBlock(256, 512, has_pool=False)

    def forward(self, x):
        pre_pool1, post_pool1 = self.block1(x)
        pre_pool2, post_pool2 = self.block2(post_pool1)
        pre_pool3, post_pool3 = self.block3(post_pool2)
        _, out = self.bottleneck(post_pool3)
        return pre_pool1, pre_pool2, pre_pool3, out

class DecoderLayer(nn.Module):
    def __init__(self, cin, cout, kernel, stride, padding):
        super().__init__()
        self.conv = nn.Conv2d(cin, cout, kernel, stride, padding)
        self.relu = nn.ReLU(inplace=True)

    def forward(self, x):
        out = self.conv(x)
        return self.relu(out)

class DecoderBlock(nn.Module):
    def __init__(self, cin, cout, up_kernel=2, up_stride=2,
                 conv_kernel=3, conv_stride=1, conv_padding=1):
        super().__init__()
        self.up = nn.ConvTranspose2d(cin, cout, up_kernel, up_stride)
        self.relu1 = nn.ReLU(inplace=True)
        self.layer1 = DecoderLayer(cout * 2, cout, conv_kernel, conv_stride, conv_padding)
        self.layer2 = DecoderLayer(cout, cout, conv_kernel, conv_stride, conv_padding)

    def forward(self, x, skip):
        out = self.up(x)
        out = self.relu1(out)
        out = torch.cat([out, skip], dim=1)
        out = self.layer1(out)
        return self.layer2(out)

class Decoder(nn.Module):
     def __init__(self):
         super().__init__()
         self.block1 = DecoderBlock(512, 256)
         self.block2 = DecoderBlock(256, 128)
         self.block3 = DecoderBlock(128, 64)
         self.final_conv = nn.ConvTranspose2d(64, 3, 1)
         self.sigmoid = nn.Sigmoid()

     def forward(self, x, skip1, skip2, skip3):
         out = self.block1(x, skip3)
         out = self.block2(out, skip2)
         out = self.block3(out, skip1)
         out = self.final_conv(out)
         return self.sigmoid(out)

class UNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.encoder = Encoder()
        self.decoder = Decoder()

    def forward(self, x):
        skip1, skip2, skip3, out = self.encoder(x)
        return self.decoder(out, skip1, skip2, skip3)

model = UNet()
dummy = torch.randn(4, 3, 32, 32)
out = model(dummy)
out.shape

device = ('cuda' if torch.cuda.is_available() else 'cpu')
device

def weighted_l1(recon, clean, mask, alpha_patch=10.0):
    diff = (recon - clean).abs()
    patch_loss = (diff * mask).sum() / mask.sum().clamp(min=1)
    bg_loss    = (diff * (1 - mask)).mean()
    return alpha_patch * patch_loss + bg_loss

lpips_fn = lpips.LPIPS(net="vgg").to(device)
def perceptual_loss(recon, clean, w_lpips=0.2):
    recon = recon * 2 - 1
    clean = clean * 2 - 1
    return w_lpips * lpips_fn(recon, clean).mean()

model = UNet().to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

num_epochs = 40

saved_model_state_path = '/kaggle/working/model_state_dict.pth'

best_val_loss = float('inf')
patience = 4
num_consecutive_bad_epochs = 0

for epoch in range(num_epochs):
    train_total = 0
    train_loss = 0.0

    model.train()

    for noisy_imgs, clean_imgs, masks in train_loader:
        noisy_imgs, clean_imgs, masks = noisy_imgs.to(device), clean_imgs.to(device), masks.to(device)
        recon_imgs = model(noisy_imgs)

        optimizer.zero_grad()
        loss = weighted_l1(recon_imgs, clean_imgs, masks)
        loss += perceptual_loss(recon_imgs, clean_imgs)

        loss.backward()
        optimizer.step()

        train_loss += loss.item() * noisy_imgs.size(0)
        train_total += noisy_imgs.size(0)

    model.eval()

    val_loss = 0.0
    val_total = 0

    with torch.no_grad():
        for noisy_imgs, clean_imgs, masks in val_loader:
            noisy_imgs, clean_imgs, masks = noisy_imgs.to(device), clean_imgs.to(device), masks.to(device)
            recon_imgs = model(noisy_imgs)

            loss = weighted_l1(recon_imgs, clean_imgs, masks)
            loss += perceptual_loss(recon_imgs, clean_imgs)

            val_loss += loss.item() * noisy_imgs.size(0)
            val_total += noisy_imgs.size(0)

    avg_train_loss = train_loss / train_total
    avg_val_loss = val_loss / val_total

    if avg_val_loss < best_val_loss:
        torch.save(model.state_dict(), saved_model_state_path)
        best_val_loss = avg_val_loss
        num_consecutive_bad_epochs = 0
    else:
        num_consecutive_bad_epochs += 1
        if (num_consecutive_bad_epochs >= patience):
            print("Early stopping")
            break

    print(f"Epoch {epoch+1}/{num_epochs} — "
          f"Train Loss: {avg_train_loss:.6f} — "
          f"Val Loss: {avg_val_loss:.6f}")

saved_model_state_path = '/kaggle/working/model_state_dict.pth'
model = UNet().to(device)
model.load_state_dict(torch.load(saved_model_state_path))

model.eval()

test_loss = 0.0
test_total = 0

with torch.no_grad():
    for noisy_imgs, clean_imgs, masks in test_loader:
        noisy_imgs, clean_imgs, masks = noisy_imgs.to(device), clean_imgs.to(device), masks.to(device)

        recon_imgs = model(noisy_imgs)
        loss = weighted_l1(recon_imgs, clean_imgs, masks)
        loss += perceptual_loss(recon_imgs, clean_imgs)

        test_loss += loss.item() * noisy_imgs.size(0)
        test_total += noisy_imgs.size(0)

print(noisy_imgs.shape, clean_imgs.shape, masks.shape)
avg_test_loss = test_loss / test_total
print(f"Test Loss: {avg_test_loss:.6f}")

model.eval()

with torch.no_grad():
    for noisy_imgs, clean_imgs, _ in test_loader:
        noisy_imgs, clean_imgs = noisy_imgs.to(device), clean_imgs.to(device)
        recon_imgs = model(noisy_imgs)
        break

noisy_imgs = noisy_imgs.detach().cpu().numpy()
recon_imgs = recon_imgs.detach().cpu().numpy()
clean_imgs = clean_imgs.detach().cpu().numpy()

num_samples = 6
fig, axes = plt.subplots(3, num_samples, figsize=(num_samples * 2, 6))

for i in range(num_samples):
    axes[0, i].imshow(np.transpose(noisy_imgs[i], (1, 2, 0)))
    axes[0, i].axis('off')
    if i == 0: axes[0, i].set_title("Noisy Input")

    axes[1, i].imshow(np.transpose(recon_imgs[i], (1, 2, 0)))
    axes[1, i].axis('off')
    if i == 0: axes[1, i].set_title("Model Output")

    axes[2, i].imshow(np.transpose(clean_imgs[i], (1, 2, 0)))
    axes[2, i].axis('off')
    if i == 0: axes[2, i].set_title("Original Clean")

plt.tight_layout()
plt.show()

